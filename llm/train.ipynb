{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bcd6257-31c4-4d9f-884c-8b763add350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b386b92-ad99-4347-920f-95b606dfe4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dataset=os.path.join(\"..\")\n",
    "dataset_dir=os.path.join(root_dataset,\"dataset\")\n",
    "dataset_train_path=os.path.join(dataset_dir,\"train\",\"Task1_2_180724_reformatted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61218eb-b9de-478b-89f4-83e7f46af22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, logging, TextStreamer\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch, platform, warnings\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8cf45c-b16a-41ee-9784-11f2d4dd2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8028/2338294619.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(4,4).to(\"cuda\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(4,4).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a09a9e6-5a63-469d-87a9-c9ffb0fbc99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of CUDA devices: 1\n",
      "--- CUDA Device 0 ---\n",
      "Name: A100-SXM-80GB\n",
      "Compute Capability: (8, 0)\n",
      "Total Memory: 85199093760 bytes\n",
      "--- CPU Information ---\n",
      "Processor: x86_64\n",
      "System: Linux 3.10.0-1160.el7.x86_64\n",
      "Python Version: 3.10.12\n"
     ]
    }
   ],
   "source": [
    "def print_system_specs():\n",
    "    # Check if CUDA is available\n",
    "    is_cuda_available = torch.cuda.is_available()\n",
    "    print(\"CUDA Available:\", is_cuda_available)\n",
    "# Get the number of available CUDA devices\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(\"Number of CUDA devices:\", num_cuda_devices)\n",
    "    if is_cuda_available:\n",
    "        for i in range(num_cuda_devices):\n",
    "            # Get CUDA device properties\n",
    "            device = torch.device('cuda', i)\n",
    "            print(f\"--- CUDA Device {i} ---\")\n",
    "            print(\"Name:\", torch.cuda.get_device_name(i))\n",
    "            print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
    "            print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
    "    # Get CPU information\n",
    "    print(\"--- CPU Information ---\")\n",
    "    print(\"Processor:\", platform.processor())\n",
    "    print(\"System:\", platform.system(), platform.release())\n",
    "    print(\"Python Version:\", platform.python_version())\n",
    "print_system_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b5fbf75-c02e-420b-b37f-e847ef1f8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre trained model\n",
    "model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\" \n",
    "\n",
    "# # Dataset name\n",
    "# dataset_name = \"vicgalle/alpaca-gpt4\"\n",
    "\n",
    "# Hugging face repository link to save fine-tuned model(Create new repository in huggingface,copy and paste here)\n",
    "new_model = \"t1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdf020f-431a-4b26-98e6-fafc6ebe7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "law_dir=os.path.join(root_dataset,\"wcx_ptt_export_280524\")\n",
    "law_list=glob.glob(os.path.join(law_dir,\"*.json\"))\n",
    "law_data = {}\n",
    "for i in law_list:\n",
    "    key=Path(i).stem\n",
    "    law_data[key]={}\n",
    "    with open(i) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    for j in json_data:\n",
    "        law_data[key][j['section_num']]=j['section_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb77d98-7ddb-404c-816c-aab53bb9476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "import pandas as pd\n",
    "df = pd.read_csv(dataset_train_path)\n",
    "ds = Dataset.from_pandas(df)\n",
    "dataset=ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed263dd-eb7e-49d3-9c52-8e8baa5febb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d225cf762c45f8a4c55b05d9dabf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model(llama-2-7b-hf) and tokenizer\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.float16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "model.config.pretraining_tp = 1\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "# tokenizer.add_bos_token, tokenizer.add_eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85fa8e07-d475-4dab-9290-03a6afc61579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'idx', 'question', 'question_ori', 'answer', 'answer_ori', 'relevant_laws', 'irrelevant_laws', 'comment_1_1', 'comment_1_2'],\n",
       "    num_rows: 2392\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580b2605-9f23-4769-854c-9f7c6f392419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90fa9d12dbc43539ff6c53cbfcf2a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'idx', 'question', 'question_ori', 'answer', 'answer_ori', 'relevant_laws', 'irrelevant_laws', 'comment_1_1', 'comment_1_2'],\n",
       "    num_rows: 2392\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dataset.filter(lambda example: isinstance(eval(example['relevant_laws']),list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a468d8a4-b27e-4a1b-ab83-530251fa7d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe8403a184c4eee90d29b3e9331b81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801ba45201c54ea783cb4de74af9e603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs       = examples[\"question\"]\n",
    "    outputs      = examples[\"answer\"]\n",
    "    list_law= [i for i in examples[\"relevant_laws\"]]\n",
    "    # list_txt_law=[]\n",
    "    # for i in list_law:\n",
    "    #     list_txt_law.append(law_data[i[\"law_code\"][str(i['sections'][0])]])\n",
    "    texts = []\n",
    "    for i, output,law in zip(inputs, outputs,list_law):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        list_txt_law=[]\n",
    "        for k in eval(law):\n",
    "            if k[\"law_code\"] not in set(law_data.keys()):\n",
    "                pass\n",
    "            else:\n",
    "                if str(k['sections'][0]) not in set(law_data[k[\"law_code\"]].keys()):\n",
    "                    pass\n",
    "                else:\n",
    "                    list_txt_law.append(law_data[k[\"law_code\"]][str(k['sections'][0])].strip())\n",
    "        if list_txt_law!=[]:\n",
    "            source_information=\"- \"+\"\\n- \".join(list_txt_law)\n",
    "            source_information=source_information.strip()\n",
    "            i=i.strip()\n",
    "            content=f\"\"\"Query: {i}\\nContinue to answer the query by using the Search Results:\\n{source_information}\"\"\"\n",
    "            text = tokenizer.apply_chat_template([{\"role\":\"user\",\"content\":content},{\"role\":\"assistant\",\"content\":output.strip()}], tokenize=False) + EOS_TOKEN\n",
    "            texts.append(text)\n",
    "        else:\n",
    "            texts.append(None)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,).filter(lambda example: isinstance(example['text'],str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4efd16be-cc49-47aa-85a3-d55fc2268ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'idx', 'question', 'question_ori', 'answer', 'answer_ori', 'relevant_laws', 'irrelevant_laws', 'comment_1_1', 'comment_1_2', 'text'],\n",
       "    num_rows: 1533\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eca1b5b-2730-4ef1-8d10-64901f4288aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Query: คณะกรรมการใดที่มีอำนาจพิจารณาอุทธรณ์เกี่ยวกับการจัดซื้อจัดจ้างภาครัฐ\n",
      "Continue to answer the query by using the Search Results:\n",
      "- พระราชบัญญัติการจัดซื้อจัดจ้างและการบริหารพัสดุภาครัฐ พ.ศ. 2560 มาตรา 43 ให้คณะกรรมการพิจารณาอุทธรณ์มีอำนาจหน้าที่ ดังต่อไปนี้\n",
      "(1) พิจารณาและวินิจฉัยอุทธรณ์ตามมาตรา 119\n",
      "(2) พิจารณาข้อร้องเรียนกรณีที่เห็นว่าหน่วยงานของรัฐมิได้ปฏิบัติให้เป็นไปตามแนวทางของพระราชบัญญัตินี้ กฎกระทรวง หรือระเบียบที่ออกตามความในพระราชบัญญัตินี้\n",
      "(3) จัดทำรายงานเกี่ยวกับปัญหาและอุปสรรคในการดำเนินการพิจารณาอุทธรณ์และข้อร้องเรียนเสนอคณะกรรมการนโยบายอย่างน้อยปีละหนึ่งครั้ง\n",
      "(4) ปฏิบัติหน้าที่อื่นตามที่กำหนดในพระราชบัญญัตินี้หรือตามที่คณะกรรมการนโยบาย รัฐมนตรี หรือคณะรัฐมนตรีมอบหมาย\n",
      "ผลการดำเนินการตาม (1) (2) และ (3) ให้ประกาศในระบบเครือข่ายสารสนเทศของกรมบัญชีกลางตามวิธีการที่กรมบัญชีกลางกำหนด\n",
      "การยื่นข้อร้องเรียนและการพิจารณาข้อร้องเรียนตาม (2) ให้เป็นไปตามระเบียบที่รัฐมนตรีกำหนด\n",
      "ในกรณีที่พิจารณาข้อร้องเรียนตาม (2) แล้วรับฟังได้ว่าหน่วยงานของรัฐมิได้ปฏิบัติตามพระราชบัญญัตินี้ หรือกฎกระทรวงหรือระเบียบที่ออกตามความในพระราชบัญญัตินี้ ให้คณะกรรมการพิจารณาอุทธรณ์มีอำนาจสั่งระงับการจัดซื้อจัดจ้างไว้ก่อนได้ เว้นแต่จะได้ลงนามในสัญญาจัดซื้อจัดจ้างแล้ว\n",
      "ในกรณีที่คณะกรรมการพิจารณาอุทธรณ์กระทำการตามหน้าที่โดยสุจริต ย่อมได้รับการคุ้มครองไม่ต้องรับผิดทั้งทางแพ่ง ทางอาญา หรือทางปกครอง<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "คำตอบ:\n",
      "\n",
      "คณะกรรมการพิจารณาอุทธรณ์ตามพระราชบัญญัติการจัดซื้อจัดจ้างและการบริหารพัสดุภาครัฐ พ.ศ. 2560 มาตรา 43 มีอำนาจพิจารณาอุทธรณ์เกี่ยวกับ การจัดซื้อจัดจ้างภาครัฐ โดยมีหน้าที่ดังนี้\n",
      "\n",
      "* พิจารณาและวินิจฉัยอุทธรณ์ตามมาตรา 119\n",
      "* พิจารณาข้อร้องเรียนกรณีที่เห็นว่าหน่วยงานของรัฐไม่ได้ปฏิบัติให้เป็นไปตามแนวทางของพระราชบัญญัตินี้ กฎกระทรวง หรือระเบียบบที่ออกตามความในพระราชบัญญัตินี้\n",
      "* จัดทำรายงานเกี่ยวกับปัญหาและอุปสรรคในการดำเนินการพิจารณาอุทธรณ์และข้อร้องเรียนเสนอคณะกรรมการนโยบายอย่างน้อยปีละหนึ่งครั้ง\n",
      "* ปฏิบัติหน้าที่อื่นตามที่กำหนดในพระราชบัญญัตินี้หรือตามที่คณะกรรมการนโยบาย รัฐมนตรี หรือคณะรัฐมนตรีมอบหมาย\n",
      "\n",
      "โดยเฉพาะสำหรับการจัดซื้อจัดจ้างภาครัฐ คณะกรรมการพิจารณาอุทธรณ์มีอำนาจสั่งระงับการจัดซื้อจัดจ้างไว้ก่อนได้ เว้นแต่จะได้ลงนามในสัญญาจัดซื้อจัดจ้างแล้ว<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"text\"][228])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d22618e-1c10-4246-9b32-dc226c5df740",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha= 8,\n",
    "    lora_dropout= 0.1,\n",
    "    r= 16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1c59f9-f82a-4bc1-a2f5-3434351755fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir= \"./results_mark2\",\n",
    "    num_train_epochs= 1,\n",
    "    per_device_train_batch_size= 8,\n",
    "    gradient_accumulation_steps= 2,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    save_steps= 1000,\n",
    "    logging_steps= 30,\n",
    "    learning_rate= 2e-4,\n",
    "    weight_decay= 0.001,\n",
    "    fp16= False,\n",
    "    bf16= False,\n",
    "    max_grad_norm= 0.3,\n",
    "    max_steps= -1,\n",
    "    warmup_ratio= 0.3,\n",
    "    group_by_length= True,\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a81d9f-34e5-41ee-be77-584d76c0bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d20d2c38a204efbab76d2c3e52fd263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= None,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e21218-ac71-4be7-81f7-71481de0758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-30 07:27:26,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwannaphong\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/law/ThaiLegalRAG/llm/wandb/run-20240730_072729-p5aqoctz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wannaphong/huggingface/runs/p5aqoctz' target=\"_blank\">./results_mark2</a></strong> to <a href='https://wandb.ai/wannaphong/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wannaphong/huggingface' target=\"_blank\">https://wandb.ai/wannaphong/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wannaphong/huggingface/runs/p5aqoctz' target=\"_blank\">https://wandb.ai/wannaphong/huggingface/runs/p5aqoctz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4/96 01:25 < 1:05:19, 0.02 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055e45f-f15e-4276-a03a-c0b07bbdb424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
